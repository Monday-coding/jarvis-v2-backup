#!/usr/bin/env python3
"""
æ¸¬è©¦ Ollama API ä¸¦ä¿®å¾©å•é¡Œ
"""

import subprocess
import json


def test_ollama():
    """æ¸¬è©¦ Ollama API"""
    
    OLLAMA_URL = "http://localhost:11434"
    MODEL = "qwen2.5:1.5b"
    
    # æ¸¬è©¦ 1ï¼šç°¡å–®æ¸¬è©¦
    print("ğŸ§ª æ¸¬è©¦ 1ï¼šç°¡å–®ç”Ÿæˆ")
    result = call_ollama("ä½ å¥½")
    print(f"çµæœï¼š{result}")
    print("")
    
    # æ¸¬è©¦ 2ï¼šJSON è¼¸å‡º
    print("ğŸ§ª æ¸¬è©¦ 2ï¼šJSON åˆ†é¡")
    prompt = """
ä½ æ˜¯å€‹åˆ†é¡å™¨ã€‚è«‹å°‡ "ä½ å¥½" åˆ†é¡ç‚º "chat" æˆ– "task"ã€‚
åªè¿”å›é¡åˆ¥è©å½™ï¼Œä¸è¦ä»»ä½•å…¶ä»–å…§å®¹ã€‚
"""
    result = call_ollama(prompt)
    print(f"çµæœï¼š{result}")
    print("")
    
    # æ¸¬è©¦ 3ï¼šçµæ§‹åŒ– JSON
    print("ğŸ§ª æ¸¬è©¦ 3ï¼šçµæ§‹åŒ– JSON")
    prompt = """
ä½ æ˜¯å€‹åˆ†é¡å™¨ã€‚è«‹å°‡ "ä½ å¥½" åˆ†é¡ã€‚
è¿”å› JSON æ ¼å¼ï¼š{"category": "chat"}
åªè¿”å› JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å…§å®¹ã€‚
"""
    result = call_ollama(prompt)
    print(f"çµæœï¼š{result}")
    print("")
    
    # æ¸¬è©¦ 4ï¼šç›´æ¥ JSON æ¨¡å¼
    print("ğŸ§ª æ¸¬è©¦ 4ï¼šä½¿ç”¨æ ¼å¼åŒ–åƒæ•¸")
    payload = {
        "model": MODEL.replace('ollama/', ''),
        "prompt": "ä½ å¥½",
        "stream": False,
        "format": "json"  # ä½¿ç”¨æ ¼å¼åŒ–åƒæ•¸
    }
    
    result = subprocess.run(
        ['curl', '-s', '-X', 'POST', f'{OLLAMA_URL}/api/generate',
         '-H', 'Content-Type: application/json',
         '-d', json.dumps(payload)],
        capture_output=True,
        text=True,
        timeout=60
    )
    
    try:
        response = json.loads(result.stdout)
        print(f"çµæœï¼š{response}")
        print("")
    except:
        print(f"åŸå§‹è¼¸å‡ºï¼š{result.stdout}")


def call_ollama(prompt):
    """èª¿ç”¨ Ollama"""
    import subprocess
    import json
    
    OLLAMA_URL = "http://localhost:11434"
    MODEL = "qwen2.5:1.5b"
    
    payload = {
        "model": MODEL.replace('ollama/', ''),
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.3,
            "max_tokens": 100
        }
    }
    
    result = subprocess.run(
        ['curl', '-s', '-X', 'POST', f'{OLLAMA_URL}/api/generate',
         '-H', 'Content-Type: application/json',
         "-d", json.dumps(payload)],
        capture_output=True,
        text=True,
        timeout=30
    )
    
    try:
        response = json.loads(result.stdout)
        return response.get('response', '')
    except:
        return result.stdout


if __name__ == "__main__":
    test_ollama()
