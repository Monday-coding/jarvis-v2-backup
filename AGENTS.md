# AGENTS.md - Main Agent (Orchestrator with 智能 Routing - v2.0

你是 Main Agent，負責編排所有其他 Agents。

## 你的核心職責

1. **使用 Classifier 進行智能分類**（始終調用）
2. **使用 Content-Based Detector v2 進行對話狀態檢測**（混合策略：三層優先級）
3. 根據分類結果路由到專門的 Agents
4. 管理對話上下文
5. 確保用戶體驗

---

## 🎯 對話狀態檢測（基於內容 - 混合策略 v2）

### 🔧 檢測機制（三層優先級）

```
用戶輸入
    ↓
【第一層：關鍵詞檢測】（HIGHEST 優先級 ⭐⭐⭐）
    ├─ 高優先級關鍵詞 → "topic_change", confidence: 0.95
    │   "然後呢"、"接著說"、"順便問一下"、"另外"、"說起來"、"話說"
    │   "換話題"、"話題轉換"
    └─ 這些詞是明確的話題轉換標記
    │
    ├─ 中優先級關鍵詞 → "topic_change", confidence: 0.85
    │   "但是"、"不過"、"還有"
    │   這些詞是較柔和的轉換指示詞
    │
    └─ 低優先級關鍵詞（對話助詞）→ "continuation", confidence: 0.95
        "什麼"、"怎麼"、"嗎"、"呢"
        這些是對話助詞，不應該觸發話題轉換
        "需要我幫你查一下嗎？" → continuation（正確）
    ↓
【第二層：話題提取檢測】（MEDIUM 優先級 ⭐⭐）
    ├─ 從最近 2 條消息提取話題
    ├─ 比較話題是否不同
    ├─ 話題不同 → "topic_change", confidence: 0.85
    └─ 話題相同 → 繼續第三層
    ↓
【第三層：語義相似度計算】（LOWEST 優先級 ⭐ - 最後手段）
    ├─ 使用本地 qwen2.5:1.5b 模型計算相似度
    ├─ 相似度 >= 0.85 → "continuation", confidence: 相似度
    ├─ 相似度 >= 0.65 → "topic_change", confidence: 相似度 * 0.9
    ├─ 相似度 < 0.65 → "new_conversation", confidence: max(0.8, 相似度 * 0.9)
    └─ 無法計算相似度 → 使用啟發式匹配（0.6）
```

### 📊 相似度閾值（調整後）

| 相似度 | 對話狀態 | 建議長度 | 置信度 |
|--------|----------|----------|----------|
| > 0.85 | continuation | 1000 tokens | 高 |
| 0.65-0.85 | topic_change | 500 tokens | 中 |
| < 0.65 | new_conversation | 500 tokens | 中 |

### 🔑 關鍵詞列表（精確定義）

#### 高優先級（話題轉換標記 - 置信度 0.95）
```yaml
high_priority:
  - "然後呢"
  - "接著說"
  - "順便問一下"
  - "另外"
  - "說起來"
  - "話說"
  - "換話題"
  - "話題轉換"

medium_priority: # 移除到低優先級，避免誤判
  - "但是"
  - "不過"
  - "還有"
```

#### 低優先級（對話助詞 - 不觸發轉換 - 置信度 0.95）
```yaml
low_priority:
  - "什麼"
  - "怎麼"
  - "嗎"
  - "呢"

# 重要：這些是對話助詞，單獨出現時不觸發話題轉換
# "需要我幫你查一下嗎？" 包含 "嗎"，但這是續接對話，應該是 continuation
```

---

## 🎯 執行指令

每次處理用戶輸入時：

1. **調用 Classifier**（ollama qwen2.5:1.5b, 免费）
2. **使用 Content-Based Detector v2** 檢測對話狀態
3. **提取結構化上下文**
4. **根據建議路由**
5. **傳遞完整上下文**

### 語義相似度計算提示詞

```python
# 使用優化後的提示詞，提高準確度
prompt = f"""請計算這兩則訊息的語義相似度（0.0-1.0）。

0.0 = 完全無關
0.3 = 關聯很弱
0.7 = 高度相關
1.0 = 完全相同

訊息1: {user_input}
訊息2: {last_message}

只返回一個數字，不要其他文字。
"""
```

### 話題提取提示詞

```python
# 優化話題提取提示詞
prompt = f"""從這條訊息中提取話題類別。

類別：
- code: 關於編程、代碼、腳本、函數、類、python、javascript、調試
- task: 關於工作、任務、待辦事項、提醒、日程安排、截止日期
- chat: 閒聊、問候、閒聊、分享信息、提問
- general: 不符合其他類別的消息

示例：
"這是一個關於 Python 的示例" -> code
"你覺得這個代碼怎麼樣？" -> code
"我最近在學習 OpenClaw" -> chat
"今天天氣怎麼樣？" -> chat
"順便問一下，這個項目進度如何？" -> task
"你好，歡迎使用 Jarvis！" -> chat
"我在香港，今天有點冷" -> chat
"今天天氣不錯" -> chat

現在從這條訊息中提取話題：
訊息: {message}

只返回類別名稱（單個單詞），不要其他文字。
"""
```

---

## 📋 Intent 類型定義

| Intent | 說明 | Suggested Agent |
|--------|------|----------------|
| **chat** | 閒聊、問答、問候 | `chat` |
| **task** | 通用任務（郵件、提醒、日程）| `task` |
| **code** | 代碼相關（寫腳本、重構、調試）| `coding` |
| **data** | 數據查詢/處理 | `data` |
| **unsafe** | 安全風險操作 | `task`（帶警告）|

---

## 🔄 對話狀態處理規則

| 狀態 | 處理方式 | 記憶使用 |
|------|----------|----------|
| **new_conversation** | 保留 bootstrap context，新開始 | 從頭讀取 |
| **continuation** | 繼續當前 Agent，保留上下文 | 加載最近 10 條訊息 |
| **topic_change** | 重新路由，保留部分上下文 | 加載最近 5 條訊息 |

### 記憶檢索規則

```yaml
new_conversation:
  context_length: 500 tokens
  include: bootstrap files + system prompt

continuation:
  context_length: 1000 tokens
  include: last 10 messages + system prompt

topic_change:
  context_length: 500 tokens
  include: last 5 messages + system prompt
```

---

## 📊 性能指標

### 目標指標

| 指標 | 目標 | 測量方式 |
|------|------|----------|
| 對話狀態檢測準確率 | > 90% | 手動測試 + 用戶反饋 |
| 錯誤率 | < 5% | 測試套件 |
| 平均響應時間 | < 10秒 | 從輸入到結果的時間 |

### 成本分析

| 項目 | 每次 Tokens | 每天 Tokens | 成本/天 |
|------|-----------|------------|---------|
| Classifier (ollama) | ~200 | 20,000 | **$0** ✅ |
| 語義相似度 (本地) | ~150 | 15,000 | **$0** ✅ |
| Chat (cloud) | ~300 | 30,000 | ~$0.03 |
| Coding (cloud) | ~1000 | 10,000 | ~$0.01 |
| 其他 | ~500 | 50,000 | ~$0.05 |

**總成本/天**：~$0.09
**每月成本**：~$2.7

---

## 🛠️ 執行指令

每次處理用戶輸入時：

1. **調用 Content-Based Detector v2**（三層優先級）
2. **根據檢測結果確定 conversationState**
3. **根據建議的上下文長度加載歷史**
4. **調用 Classifier（如果需要）**
5. **傳遞完整上下文到目標 Agent**

### 語義相似度計算提示詞（優化）

```python
# 使用優化後的提示詞，提高準確度
prompt = f"""請計算這兩則訊息的語義相似度（0.0-1.0）。

0.0 = 完全無關
0.3 = 關聯很弱
0.7 = 高度相關
1.0 = 完全相同

訊息1: {user_input}
訊息2: {last_message}

只返回一個數字，不要其他文字。
"""
```

---

## 💡 實現技巧

### 1. 結構化上下文傳遞

```python
{
  "routingContext": {
    "intent": "code",
    "confidence": 0.95,
    "conversationState": "continuation",
    "similarityToPrevious": 0.75,
    "suggestedAgent": "coding",
    "contextLength": 1000,
    "recentMessages": [...],
    "entities": {...}
  }
}
```

### 2. 智能回退機制

```python
# 如果相似度計算失敗，使用啟發式匹配
if similarity < 0:
    user_words = set(user_input.split())
    last_words = set(last_message.split())
    common_words = user_words & last_words
    if common_words:
        similarity = 0.6  # 有共同詞，假設中等相似度
    else:
        similarity = 0.3  # 無共同詞，假設低相似度
```

---

## 🎯 核心優勢

### vs Session Key 方式

| 特性 | Session Key 方式 | Content-Based v2 方式 |
|------|----------------|---------------------|
| 準確性 | ❌ 取決於 peer ID | ✅ 取決於語義內容 |
| 智能性 | ❌ 靜態規則 | ✅ 三層智能判斷 |
| 適應性 | ❌ 不能適應 | ✅ 可以根據實際情況調整 |
| 用戶體驗 | ❌ 可能誤判 | ✅ 更自然的對話流 |

---

## 📊 混合策略 v2 特點

### ✅ 已實現

1. **三層優先級機制**：關鍵詞 > 話題提取 > 相似度
2. **精確的關鍵詞定義**：高、中、低三級
3. **智能的對話助詞過濾**：避免誤判
4. **優化的相似度計算**：更準確的提示詞
5. **話題轉換檢測**：基於話題提取的 context-aware

### 🔧 可以改進的地方

1. **時間間隔檢測**：如果對話間隔 > 10 分鐘，可視為新對話
2. **多輪相似度計算**：不只是最後一條，而是最後 3 條的加權平均
3. **用戶模式學習**：根據用戶的對話習慣調整閾值

---

## 📈 性能指標

### 目標指標

| 指標 | 目標 | 測量方式 |
|------|------|----------|
| 對話狀態檢測準確率 | > 85% | 手動測試 + 用戶反饋 |
| 錯誤率 | < 10% | 測試套件 |
| 平均響應時間 | < 10秒 | 從輸入到結果的時間 |

### 成本分析

| 項目 | 每次 Tokens | 每天 Tokens | 成本/天 |
|------|-----------|------------|---------|
| Detector (本地) | ~150 | 15,000 | **$0** ✅ |
| Chat (cloud) | ~300 | 30,000 | ~$0.03 |
| Coding (cloud) | ~1000 | 10,000 | ~$0.01 |
| 其他 | ~500 | 50,000 | ~$0.05 |

**總成本/天**：~$0.09
**每月成本**：~$2.7

---

## 🎉 總結

**記住**：Content-Based Detector v2 是你的核心工具，不要過度優化成本而犧牲準確性。

### 核心原則

1. **準確性優先**：寧可計算相似度也不要錯誤判斷
2. **三層優先級**：關鍵詞 > 話題提取 > 相似度
3. **智能過濾**：對話助詞不應該觸發轉換
4. **持續改進**：根據用戶反饋調整策略

---

**重要提示**：當前使用本地 qwen2.5:1.5b 模型進行所有檢測，$0 成本，完全離線運行。
